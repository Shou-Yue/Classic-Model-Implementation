{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the paper for more detail. <BR>\n",
    "Reference: https://ieeexplore.ieee.org/abstract/document/5197422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix_Factorization:\n",
    "    def __init__(self, alpha = 0.00001, iterations = 50, num_of_latent = 200, lam = 0.0005):\n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "            \n",
    "            attributes: \n",
    "                        alpha: Learning Rate, default 0.01\n",
    "                        num_iter: Number of Iterations to update coefficient with training data\n",
    "                        num_of_latent: Number of latent factor.\n",
    "                        lam: Regularization constant\n",
    "                        \n",
    "            \n",
    "            TODO: 1. Initialize all variables needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.num_of_latent = num_of_latent\n",
    "        self.lam = lam\n",
    "        \n",
    "    def fit(self, train):\n",
    "        \"\"\"\n",
    "            Train: list of tuples with (User, Movie, Rating)\n",
    "            num_user: Number of unique user.\n",
    "            num_movie: Number of unique movie\n",
    "            \n",
    "            TODO: 2. Initialize num_user and num_movie\n",
    "                  3. Save the training set.\n",
    "                  4. Initialize P and Q matrix, with normal distribution with mean = 0. \n",
    "                  Hint: Think about what P and Q represent, what they should do.Think about the shape too. \n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        num_user = int(max([t[0] for t in train])) + 1\n",
    "        num_movie = int(max([t[1] for t in train])) + 1\n",
    "        self.train = train\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "        \n",
    "        self.P = np.random.normal(scale=0.1, size=(num_user, self.num_of_latent))\n",
    "        self.Q = np.random.normal(scale=0.1, size=(num_movie, self.num_of_latent))\n",
    "        \n",
    "        rmse_lst = []\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 5: Calculate the error, using P and Q matrix. \n",
    "                  6: We need to check if the absolute value error is less than some constant. Store the previous Q and P for adaptive learning rate.\n",
    "                      If it is less than that constant then we update P and Q matrix. \n",
    "                      (When update, update the P and Q at the same time. Think about why it is important.)\n",
    "                      Otherwise use the error to update the Q and P matrix.\n",
    "                      \n",
    "                  7: For each entry update temp_mse, and append the Current iteration RMSE to rmse_lst.\n",
    "                  \n",
    "        \"\"\"\n",
    " \n",
    "        for f in range(self.iterations):\n",
    "            ### Random Shuffle. Why is this called?\n",
    "            np.random.shuffle(self.train)\n",
    "            \n",
    "            temp_mse = 0\n",
    "\n",
    "            previous_Q = self.Q.copy()\n",
    "            previous_P = self.P.copy()\n",
    "            \n",
    "            Count = 0\n",
    "   \n",
    "            for tup in self.train:\n",
    "                u,i,rating = tup\n",
    "                error = rating - np.dot(self.P[u], self.Q[i])\n",
    "                \n",
    "                if abs(error) > 20:\n",
    "                    continue\n",
    "\n",
    "                Count += 1\n",
    "                temp_mse += error ** 2\n",
    "                \n",
    "                pu = self.P[u].copy()\n",
    "                qi = self.Q[i].copy()\n",
    "                \n",
    "                self.P[u] = pu + self.alpha * (error * qi - self.lam * pu)\n",
    "                self.Q[i] = qi + self.alpha * (error * pu - self.lam * qi)\n",
    "                \n",
    "                #### Don't Modify this code, helpful for converge.\n",
    "                if (np.isinf(self.P[u]).any() or np.isnan(self.P[u]).any() or \n",
    "                    np.isinf(self.Q[i]).any() or np.isnan(self.Q[i]).any()):\n",
    "                    self.P[u] = pu\n",
    "                    self.Q[i] = qi\n",
    "            \n",
    "            if Count > 0:\n",
    "                rmse = np.sqrt(temp_mse / Count)\n",
    "            else:\n",
    "                rmse = float('inf')\n",
    "            rmse_lst.append(rmse)\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "                TODO: 8: Implement the adaptive learning rate.\n",
    "                         If current rmse is less than previous iteration, let's increase by a factor range from 1 - 1.5\n",
    "                         Otherwise we decrease by a factor range from 0.5 - 1\n",
    "                      9: If the current rmse is greater than previous iteration.\n",
    "                         Check the relative error, (previous - current)/ previous.\n",
    "                         If it is greater than 0.1, we restore the previous Q and P. (Try without it. Think about why we need this.)\n",
    "            \"\"\"\n",
    "            if f > 0:\n",
    "                previous_rmse = rmse_lst[f-1]\n",
    "                current_rmse = rmse_lst[f]\n",
    "                if current_rmse < previous_rmse:\n",
    "                    self.alpha *= 1.2\n",
    "                else:\n",
    "                    self.alpha *= 0.8\n",
    "                    if previous_rmse > 0 and ((previous_rmse - current_rmse) / previous_rmse > 0.1):\n",
    "                        self.P = previous_P\n",
    "                        self.Q = previous_Q\n",
    "                \n",
    "        self.rmse = rmse_lst\n",
    "        \n",
    "    def ind_predict(self, tup):\n",
    "        \"\"\"\n",
    "            tup: One single entry, (user, movie)\n",
    "            \n",
    "            TODO: 10: Use P and Q to make prediction on single entry.\n",
    "            \n",
    "        \"\"\"\n",
    "        u,i = int(tup[0]), int(tup[1])\n",
    "        return np.dot(self.P[u, :], self.Q[i, :])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X: list of entries\n",
    "            \n",
    "            TODO: 11: Use ind_predict we create to make predicitons.\n",
    "        \"\"\"\n",
    "        return [self.ind_predict(tup) for tup in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/fh_657xx0p33nz_x8d0yxd300000gn/T/ipykernel_22560/1764614809.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_userId = list(ratings.groupby(['userId']).apply(lambda x: x[['movieId','rating']].values))\n",
      "/var/folders/8y/fh_657xx0p33nz_x8d0yxd300000gn/T/ipykernel_22560/1764614809.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_movieId = list(ratings.groupby(['movieId']).apply(lambda x: x[['userId','rating']].values))\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "ratings = ratings.sort_values('timestamp').reset_index(drop = True).astype(int)\n",
    "a = np.sort(ratings.movieId.unique())\n",
    "index_dict = {}\n",
    "for i in range(len(a)):\n",
    "    index_dict[a[i]]  = i\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: index_dict[x]) \n",
    "\n",
    "grouped_userId = list(ratings.groupby(['userId']).apply(lambda x: x[['movieId','rating']].values))\n",
    "grouped_movieId = list(ratings.groupby(['movieId']).apply(lambda x: x[['userId','rating']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train = set()\n",
    "test = set()\n",
    "\n",
    "for i in range(len(grouped_movieId)):\n",
    "    temp_len = len(grouped_movieId[i])\n",
    "    for j in range(temp_len):\n",
    "        if j < temp_len * 0.8:\n",
    "            train.add((grouped_movieId[i][j][0]-1,i - 1, grouped_movieId[i][j][1]))\n",
    "        else:\n",
    "            test.add((grouped_movieId[i][j][0] -1, i - 1,grouped_movieId[i][j][1]))\n",
    "train = list(train)\n",
    "test = list(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to understand what is done for data cleaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you are doing things correctly (with tuning), you will get something lower than 1.1 test RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = Matrix_Factorization(iterations =70, num_of_latent = 100, lam = 0.1)\n",
    "clf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = 0\n",
    "pred = clf.predict(test)\n",
    "for i in range(len(test)):\n",
    "    error += (test[i][2] - pred[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0696613592540112)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error/ len(test))** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix_Factorization_with_bias:\n",
    "    def __init__(self, alpha = 0.00001, iterations = 50, num_of_latent = 200, lam = 0.01):\n",
    "        \n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "            \n",
    "            attributes: \n",
    "                        alpha: Learning Rate, default 0.01\n",
    "                        num_iter: Number of Iterations to update coefficient with training data\n",
    "                        num_of_latent: Number of latent factor.\n",
    "                        lam: Regularization constant\n",
    " \n",
    "            \n",
    "            TODO: 1. Initialize all variables needed.\n",
    "        \"\"\"\n",
    "            \n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.num_of_latent = num_of_latent\n",
    "        self.lam = lam\n",
    "\n",
    "\n",
    "        \n",
    "    def fit(self, train):\n",
    "        \"\"\"\n",
    "            Train: list of tuples with (User, Movie, Rating)\n",
    "            num_user: Number of unique user.\n",
    "            num_movie: Number of unique movie\n",
    "            \n",
    "            TODO: 2. Initialize num_user and num_movie.\n",
    "                  3. Save the training set.\n",
    "                  4. Initialize bu , bi and b. b is the global mean of the rating.\n",
    "                  5. Initialize P and Q matrix. \n",
    "                  Hint: Think about what P and Q represent, what they should do.Think about the shape too. \n",
    "                  \n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        num_user = int(max([t[0] for t in train])) + 1\n",
    "        num_movie = int(max([t[1] for t in train])) + 1\n",
    "        self.train = train\n",
    "        \n",
    "        self.P = np.random.normal(0, 0.1, (num_user, self.num_of_latent))\n",
    "        self.Q = np.random.normal(0, 0.1, (num_movie, self.num_of_latent))\n",
    "        \n",
    "        self.bu = np.zeros(num_user)\n",
    "        self.bi = np.zeros(num_movie)\n",
    "        self.b = np.mean([t[2] for t in train])\n",
    "        \n",
    "        rmse_lst = []\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 5: Calculate the error, using P , Q , bu , bi and b. \n",
    "                  6: Update the P , Q , bu , bi and b with error you calculate. \n",
    "                    (Think about why we don't need to check the absolute of error)\n",
    "                  7: For each entry update temp_mse, and append the Current iteration RMSE to rmse_lst.\n",
    "                  \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        for f in range(self.iterations):\n",
    "            \n",
    "            np.random.shuffle(self.train)\n",
    "            \n",
    "            temp_mse = 0\n",
    "            previous_Q = self.Q.copy()\n",
    "            previous_P = self.P.copy()\n",
    "            previous_bu = self.bu.copy()\n",
    "            previous_bi = self.bi.copy()\n",
    "            previous_b = self.b\n",
    "            \n",
    "            Count = 0\n",
    "            for tup in self.train:\n",
    "                u,i,rating = tup\n",
    "                \n",
    "                error = rating - (self.b + self.bu[u] + self.bi[i] + np.dot(self.P[u], self. Q[i]))         \n",
    "\n",
    "                Count += 1   \n",
    "                temp_mse += error ** 2\n",
    "                \n",
    "                self.bu[u] += self.alpha * (error - self.lam * self.bu[u])\n",
    "                self.bi[i] += self.alpha * (error - self.lam * self.bi[i])\n",
    "                self.b += self.alpha * error\n",
    "                \n",
    "                temp_P = self.P[u].copy()\n",
    "                \n",
    "                self.P[u] += self.alpha * (error * self.Q[i] - self.lam * self.P[u])\n",
    "                self.Q[i] += self.alpha * (error * temp_P - self.lam * self.Q[i])\n",
    "                \n",
    "            \n",
    "            if Count > 0:\n",
    "                rmse = np.sqrt(temp_mse / Count)\n",
    "            else:\n",
    "                rmse = float('inf')\n",
    "            rmse_lst.append(rmse)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "                TODO: 8: Implement the adaptive learning rate.\n",
    "                         If current rmse is less than previous iteration, let's increase by a factor range from 1 - 1.5\n",
    "                         Otherwise we decrease by a factor range from 0.5 - 1\n",
    "                      9: If the current rmse is greater than previous iteration.\n",
    "                         Check the relative error, (previous - current)/ previous.\n",
    "                         If it is greater than 0.1, we restore the previous Q and P. (Try without it. Think about why we need this.)\n",
    "            \"\"\"\n",
    "                \n",
    "            \n",
    "            if f > 0:\n",
    "                previous_rmse = rmse_lst[f-1]\n",
    "                current_rmse = rmse_lst[f]\n",
    "                if current_rmse < previous_rmse:\n",
    "                    self.alpha *= 1.1\n",
    "                else:\n",
    "                    self.alpha *= 0.9\n",
    "                    if previous_rmse > 0 and ((previous_rmse - current_rmse) / previous_rmse > 0.1):\n",
    "                        self.P = previous_P\n",
    "                        self.Q = previous_Q\n",
    "                        self.bu = previous_bu\n",
    "                        self.bi = previous_bi\n",
    "                        self.b = previous_b\n",
    "            print(f\"Iteration {f+1}/{self.iterations}, RMSE: {rmse:.4f}, alpha: {self.alpha:.6f}\")  \n",
    "                    \n",
    "            \n",
    "            \n",
    "        self.rmse = rmse_lst\n",
    "            \n",
    "    def ind_predict(self, tup):\n",
    "        \"\"\"\n",
    "            tup: One single entry, (user, movie)\n",
    "            \n",
    "            TODO: 10: Use P and Q to make prediction on single entry.\n",
    "            \n",
    "        \"\"\"\n",
    "        u,i = tup[0], tup[1]\n",
    "        return self.b + self.bu[u] + self.bi[i] + np.dot(self.P[u], self.Q[i])\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X: list of entries\n",
    "            \n",
    "            TODO: 11: Use ind_predict we create to make predicitons.\n",
    "        \"\"\"\n",
    "        return [self.ind_predict(tup) for tup in X]\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are doing thing correctly (With tuning), you should get a Test RMSE below 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/70, RMSE: 1.0865, alpha: 0.000010\n",
      "Iteration 2/70, RMSE: 1.0855, alpha: 0.000011\n",
      "Iteration 3/70, RMSE: 1.0844, alpha: 0.000012\n",
      "Iteration 4/70, RMSE: 1.0833, alpha: 0.000013\n",
      "Iteration 5/70, RMSE: 1.0821, alpha: 0.000015\n",
      "Iteration 6/70, RMSE: 1.0807, alpha: 0.000016\n",
      "Iteration 7/70, RMSE: 1.0793, alpha: 0.000018\n",
      "Iteration 8/70, RMSE: 1.0777, alpha: 0.000019\n",
      "Iteration 9/70, RMSE: 1.0761, alpha: 0.000021\n",
      "Iteration 10/70, RMSE: 1.0743, alpha: 0.000024\n",
      "Iteration 11/70, RMSE: 1.0724, alpha: 0.000026\n",
      "Iteration 12/70, RMSE: 1.0704, alpha: 0.000029\n",
      "Iteration 13/70, RMSE: 1.0682, alpha: 0.000031\n",
      "Iteration 14/70, RMSE: 1.0659, alpha: 0.000035\n",
      "Iteration 15/70, RMSE: 1.0635, alpha: 0.000038\n",
      "Iteration 16/70, RMSE: 1.0609, alpha: 0.000042\n",
      "Iteration 17/70, RMSE: 1.0582, alpha: 0.000046\n",
      "Iteration 18/70, RMSE: 1.0553, alpha: 0.000051\n",
      "Iteration 19/70, RMSE: 1.0524, alpha: 0.000056\n",
      "Iteration 20/70, RMSE: 1.0492, alpha: 0.000061\n",
      "Iteration 21/70, RMSE: 1.0460, alpha: 0.000067\n",
      "Iteration 22/70, RMSE: 1.0427, alpha: 0.000074\n",
      "Iteration 23/70, RMSE: 1.0392, alpha: 0.000081\n",
      "Iteration 24/70, RMSE: 1.0356, alpha: 0.000090\n",
      "Iteration 25/70, RMSE: 1.0320, alpha: 0.000098\n",
      "Iteration 26/70, RMSE: 1.0282, alpha: 0.000108\n",
      "Iteration 27/70, RMSE: 1.0244, alpha: 0.000119\n",
      "Iteration 28/70, RMSE: 1.0205, alpha: 0.000131\n",
      "Iteration 29/70, RMSE: 1.0167, alpha: 0.000144\n",
      "Iteration 30/70, RMSE: 1.0127, alpha: 0.000159\n",
      "Iteration 31/70, RMSE: 1.0087, alpha: 0.000174\n",
      "Iteration 32/70, RMSE: 1.0047, alpha: 0.000192\n",
      "Iteration 33/70, RMSE: 1.0007, alpha: 0.000211\n",
      "Iteration 34/70, RMSE: 0.9966, alpha: 0.000232\n",
      "Iteration 35/70, RMSE: 0.9926, alpha: 0.000255\n",
      "Iteration 36/70, RMSE: 0.9885, alpha: 0.000281\n",
      "Iteration 37/70, RMSE: 0.9844, alpha: 0.000309\n",
      "Iteration 38/70, RMSE: 0.9804, alpha: 0.000340\n",
      "Iteration 39/70, RMSE: 0.9762, alpha: 0.000374\n",
      "Iteration 40/70, RMSE: 0.9721, alpha: 0.000411\n",
      "Iteration 41/70, RMSE: 0.9679, alpha: 0.000453\n",
      "Iteration 42/70, RMSE: 0.9638, alpha: 0.000498\n",
      "Iteration 43/70, RMSE: 0.9596, alpha: 0.000548\n",
      "Iteration 44/70, RMSE: 0.9553, alpha: 0.000602\n",
      "Iteration 45/70, RMSE: 0.9511, alpha: 0.000663\n",
      "Iteration 46/70, RMSE: 0.9467, alpha: 0.000729\n",
      "Iteration 47/70, RMSE: 0.9424, alpha: 0.000802\n",
      "Iteration 48/70, RMSE: 0.9380, alpha: 0.000882\n",
      "Iteration 49/70, RMSE: 0.9334, alpha: 0.000970\n",
      "Iteration 50/70, RMSE: 0.9290, alpha: 0.001067\n",
      "Iteration 51/70, RMSE: 0.9244, alpha: 0.001174\n",
      "Iteration 52/70, RMSE: 0.9197, alpha: 0.001291\n",
      "Iteration 53/70, RMSE: 0.9149, alpha: 0.001420\n",
      "Iteration 54/70, RMSE: 0.9100, alpha: 0.001562\n",
      "Iteration 55/70, RMSE: 0.9050, alpha: 0.001719\n",
      "Iteration 56/70, RMSE: 0.8999, alpha: 0.001891\n",
      "Iteration 57/70, RMSE: 0.8944, alpha: 0.002080\n",
      "Iteration 58/70, RMSE: 0.8889, alpha: 0.002288\n",
      "Iteration 59/70, RMSE: 0.8830, alpha: 0.002516\n",
      "Iteration 60/70, RMSE: 0.8769, alpha: 0.002768\n",
      "Iteration 61/70, RMSE: 0.8700, alpha: 0.003045\n",
      "Iteration 62/70, RMSE: 0.8629, alpha: 0.003349\n",
      "Iteration 63/70, RMSE: 0.8552, alpha: 0.003684\n",
      "Iteration 64/70, RMSE: 0.8463, alpha: 0.004053\n",
      "Iteration 65/70, RMSE: 0.8369, alpha: 0.004458\n",
      "Iteration 66/70, RMSE: 0.8258, alpha: 0.004904\n",
      "Iteration 67/70, RMSE: 0.8132, alpha: 0.005394\n",
      "Iteration 68/70, RMSE: 0.7986, alpha: 0.005933\n",
      "Iteration 69/70, RMSE: 0.7816, alpha: 0.006527\n",
      "Iteration 70/70, RMSE: 0.7616, alpha: 0.007180\n",
      "CPU times: user 37.1 s, sys: 5.18 s, total: 42.2 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = Matrix_Factorization_with_bias(iterations =70, num_of_latent = 80, lam = 0.01)\n",
    "clf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "pred = clf.predict(test)\n",
    "for i in range(len(test)):\n",
    "    error += (test[i][2] - pred[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9590916371607499)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error/ len(test))** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc148",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
